{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a new csv file containing unique restaurants from inspections with a bunch of useful features and computed risk score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='red'>\n",
    "#### We want kind of that fields\n",
    ">restaurants_corpus = pd.DataFrame(columns = \n",
    "                                            \n",
    "                                            ['restaurant licence',\\\n",
    "                                             'latitude',\\\n",
    "                                             'longitude',\\\n",
    "                                             'community area',\\\n",
    "                                             'restaurant name',\\\n",
    "                                             'rate of failed inspections',\\\n",
    "                                             'rate of successful inspections',\\\n",
    "                                             'Average nbr of important violations',\\\n",
    "                                             'Food chain flag', \\\n",
    "                                             'nbr risk_related words computed from inspectors comments',\\\n",
    "                                             'Risk_score'])\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read the necessary cleaned datasets to keep the selected features\n",
    "cfi_dataset = pd.read_pickle('datasets/cleaned_inspections.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfi_dataset_selected = cfi_dataset[['Inspection ID', 'DBA Name', 'AKA Name', 'License #', 'Latitude', 'Longitude', \n",
    "                                    'Location', 'Community Area', 'Inspection Date', 'Results', 'Risk', \n",
    "                                    'Violation Numbers', 'Violation Comments']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we examined earlier in the Milestone2, as shown below \n",
    "<img src=\"datasets/countresult.png\" style=\"height:200px\"> \n",
    "\n",
    "here we keep only the data with \"Pass\", \"Fail\", \"Pass w/ Conditions\" results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the wanted results from data \n",
    "cfi_dataset_selected = cfi_dataset_selected[cfi_dataset_selected['Results'].isin(['Pass', \"Fail\", \"Pass w/ Conditions\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's eliminate the violations with NaN values from the data because our risk score analysis will be based on violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfi_dataset_selected = cfi_dataset_selected[~pd.isnull(cfi_dataset_selected['Violation Numbers'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfi_dataset_selected = cfi_dataset_selected.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfi_dataset_selected = cfi_dataset_selected.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of violation counts\n",
    "cfi_dataset_selected['Violation Counts'] = [len(cfi_dataset_selected['Violation Numbers'][i]) for i in range(len(cfi_dataset_selected))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of violation counts according to some gradings \n",
    "# source: https://www1.nyc.gov/assets/doh/downloads/pdf/rii/how-we-score-grade.pdf\n",
    "'''\n",
    "count the violation numbers for each inspection:\n",
    "if there is violation number between 0 and 13 points it will be counted as 'Critical Violations Count'\n",
    "if there is violation number between 14 and 27 points it will be counted as 'Moderate Violations Count'\n",
    "if there is violation number between 28 and more points it will be counted as 'Non-Critical Violations Count'\n",
    "'''\n",
    "\n",
    "cfi_dataset_selected['Critical Violations Count'] = [int(len([ i for i in cfi_dataset_selected['Violation Numbers'][k] if i<14])) for k in range(len(cfi_dataset_selected))]\n",
    "cfi_dataset_selected['Moderate Violations Count'] = [int(len([ i for i in cfi_dataset_selected['Violation Numbers'][k] if i>13 and i<28])) for k in range(len(cfi_dataset_selected))]\n",
    "cfi_dataset_selected['Non-Critical Violations Count'] = [int(len([ i for i in cfi_dataset_selected['Violation Numbers'][k] if i>27])) for k in range(len(cfi_dataset_selected))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding Allergen flag to the dataset\n",
    "cfi_dataset_selected['Allergen Flag'] = np.nan\n",
    "for i in range(len(cfi_dataset_selected)):\n",
    "    each_comment[i] = pd.Series([x.strip() for x in cfi_dataset_selected['Violation Comments'][i]])\n",
    "    if (each_comment[i].astype(str).str.contains('ALLERGEN', flags=re.IGNORECASE, regex=True)== True).any():\n",
    "        cfi_dataset_selected['Allergen Flag'][i] = 'Y'\n",
    "    else: \n",
    "        cfi_dataset_selected['Allergen Flag'][i] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Vomit or Diarrheal Events Flag to the dataset\n",
    "cfi_dataset_selected['Vomit or Diarrheal Flag'] = np.nan\n",
    "for i in range(len(cfi_dataset_selected)):\n",
    "    each_comment[i] = pd.Series([x.strip() for x in cfi_dataset_selected['Violation Comments'][i]])\n",
    "    if (each_comment[i].astype(str).str.contains('VOMIT', flags=re.IGNORECASE, regex=True)== True).any():\n",
    "        cfi_dataset_selected['Vomit or Diarrheal Flag'][i] = 'Y'\n",
    "    elif (each_comment[i].astype(str).str.contains('DIARRHEAL', flags=re.IGNORECASE, regex=True)== True).any():\n",
    "        cfi_dataset_selected['Vomit or Diarrheal Flag'][i] = 'Y'\n",
    "    else:\n",
    "        cfi_dataset_selected['Vomit or Diarrheal Flag'][i] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inspection ID</th>\n",
       "      <th>DBA Name</th>\n",
       "      <th>AKA Name</th>\n",
       "      <th>License #</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Community Area</th>\n",
       "      <th>Inspection Date</th>\n",
       "      <th>Results</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Violation Numbers</th>\n",
       "      <th>Violation Comments</th>\n",
       "      <th>Violation Counts</th>\n",
       "      <th>Allergen Flag</th>\n",
       "      <th>Vomit or Diarrheal Flag</th>\n",
       "      <th>Critical Violations Count</th>\n",
       "      <th>Moderate Violations Count</th>\n",
       "      <th>Non-Critical Violations Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2345318</td>\n",
       "      <td>SUBWAY</td>\n",
       "      <td>SUBWAY</td>\n",
       "      <td>2529116</td>\n",
       "      <td>41.927995</td>\n",
       "      <td>-87.785752</td>\n",
       "      <td>41.92799528871574, -87.78575236468352</td>\n",
       "      <td>Belmont Cragin</td>\n",
       "      <td>2019-11-08</td>\n",
       "      <td>Pass w/ Conditions</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 5, 58]</td>\n",
       "      <td>[ 2-102.14(O)  OBSERVED NO WRITTEN EMPLOYEE HE...</td>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2321166</td>\n",
       "      <td>SUBWAY</td>\n",
       "      <td>SUBWAY</td>\n",
       "      <td>2529116</td>\n",
       "      <td>41.927995</td>\n",
       "      <td>-87.785752</td>\n",
       "      <td>41.92799528871574, -87.78575236468352</td>\n",
       "      <td>Belmont Cragin</td>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>Fail</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 5, 10, 22, 33, 57, 58]</td>\n",
       "      <td>[ OBSERVED NO WRITTEN EMPLOYEE HEALTH POLICY O...</td>\n",
       "      <td>7</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2290717</td>\n",
       "      <td>PAPA JOHN'S PIZZA</td>\n",
       "      <td>PAPA JOHN'S PIZZA</td>\n",
       "      <td>1545897</td>\n",
       "      <td>41.927995</td>\n",
       "      <td>-87.785752</td>\n",
       "      <td>41.92799528871574, -87.78575236468352</td>\n",
       "      <td>Belmont Cragin</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>Pass w/ Conditions</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 5]</td>\n",
       "      <td>[ OBSERVED NO EMPLOYEE HEALTH POLICY ON THE PR...</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2144588</td>\n",
       "      <td>SUBWAY</td>\n",
       "      <td>SUBWAY</td>\n",
       "      <td>2529116</td>\n",
       "      <td>41.927995</td>\n",
       "      <td>-87.785752</td>\n",
       "      <td>41.92799528871574, -87.78575236468352</td>\n",
       "      <td>Belmont Cragin</td>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>Fail</td>\n",
       "      <td>1</td>\n",
       "      <td>[16, 34, 42]</td>\n",
       "      <td>[ OBSERVED BLACK AND PINK MOLD LIKE SUBSTANCES...</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2064444</td>\n",
       "      <td>PAPA JOHN'S PIZZA</td>\n",
       "      <td>PAPA JOHN'S PIZZA</td>\n",
       "      <td>1545897</td>\n",
       "      <td>41.927995</td>\n",
       "      <td>-87.785752</td>\n",
       "      <td>41.92799528871574, -87.78575236468352</td>\n",
       "      <td>Belmont Cragin</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>Pass</td>\n",
       "      <td>2</td>\n",
       "      <td>[32, 33, 34, 35, 37, 43, 45]</td>\n",
       "      <td>[   Inspector Comments,  Inspector Comments,  ...</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Inspection ID           DBA Name           AKA Name  License #   Latitude  \\\n",
       "0        2345318             SUBWAY             SUBWAY    2529116  41.927995   \n",
       "1        2321166             SUBWAY             SUBWAY    2529116  41.927995   \n",
       "2        2290717  PAPA JOHN'S PIZZA  PAPA JOHN'S PIZZA    1545897  41.927995   \n",
       "3        2144588             SUBWAY             SUBWAY    2529116  41.927995   \n",
       "4        2064444  PAPA JOHN'S PIZZA  PAPA JOHN'S PIZZA    1545897  41.927995   \n",
       "\n",
       "   Longitude                               Location  Community Area  \\\n",
       "0 -87.785752  41.92799528871574, -87.78575236468352  Belmont Cragin   \n",
       "1 -87.785752  41.92799528871574, -87.78575236468352  Belmont Cragin   \n",
       "2 -87.785752  41.92799528871574, -87.78575236468352  Belmont Cragin   \n",
       "3 -87.785752  41.92799528871574, -87.78575236468352  Belmont Cragin   \n",
       "4 -87.785752  41.92799528871574, -87.78575236468352  Belmont Cragin   \n",
       "\n",
       "  Inspection Date             Results  Risk             Violation Numbers  \\\n",
       "0      2019-11-08  Pass w/ Conditions     1                    [3, 5, 58]   \n",
       "1      2019-11-06                Fail     1    [3, 5, 10, 22, 33, 57, 58]   \n",
       "2      2019-05-30  Pass w/ Conditions     2                        [3, 5]   \n",
       "3      2018-02-06                Fail     1                  [16, 34, 42]   \n",
       "4      2017-06-16                Pass     2  [32, 33, 34, 35, 37, 43, 45]   \n",
       "\n",
       "                                  Violation Comments  Violation Counts  \\\n",
       "0  [ 2-102.14(O)  OBSERVED NO WRITTEN EMPLOYEE HE...                 3   \n",
       "1  [ OBSERVED NO WRITTEN EMPLOYEE HEALTH POLICY O...                 7   \n",
       "2  [ OBSERVED NO EMPLOYEE HEALTH POLICY ON THE PR...                 2   \n",
       "3  [ OBSERVED BLACK AND PINK MOLD LIKE SUBSTANCES...                 3   \n",
       "4  [   Inspector Comments,  Inspector Comments,  ...                 7   \n",
       "\n",
       "  Allergen Flag Vomit or Diarrheal Flag  Critical Violations Count  \\\n",
       "0             Y                       Y                          2   \n",
       "1             Y                       Y                          3   \n",
       "2             N                       Y                          2   \n",
       "3             N                       N                          0   \n",
       "4             N                       N                          0   \n",
       "\n",
       "   Moderate Violations Count  Non-Critical Violations Count  \n",
       "0                          0                              1  \n",
       "1                          1                              3  \n",
       "2                          0                              0  \n",
       "3                          1                              2  \n",
       "4                          0                              7  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfi_dataset_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfi_dataset_selected.to_pickle('pickles/cfi_dataset_selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfi_dataset_selected_pickle = pd.read_pickle('pickles/cfi_dataset_selected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can drop 'Violation Comments' column, because we do not need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfi_dataset_selected_pickle = cfi_dataset_selected_pickle.drop(['Violation Comments' ] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inspection ID</th>\n",
       "      <th>License #</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Violation Counts</th>\n",
       "      <th>Critical Violations Count</th>\n",
       "      <th>Moderate Violations Count</th>\n",
       "      <th>Non-Critical Violations Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.182300e+05</td>\n",
       "      <td>1.182300e+05</td>\n",
       "      <td>118230.000000</td>\n",
       "      <td>118230.000000</td>\n",
       "      <td>118230.000000</td>\n",
       "      <td>118230.000000</td>\n",
       "      <td>118230.000000</td>\n",
       "      <td>118230.000000</td>\n",
       "      <td>118230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.455131e+06</td>\n",
       "      <td>1.595582e+06</td>\n",
       "      <td>41.883736</td>\n",
       "      <td>-87.676102</td>\n",
       "      <td>1.295957</td>\n",
       "      <td>4.414971</td>\n",
       "      <td>0.419893</td>\n",
       "      <td>0.379421</td>\n",
       "      <td>3.615656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.388562e+05</td>\n",
       "      <td>9.020764e+05</td>\n",
       "      <td>0.079277</td>\n",
       "      <td>0.059985</td>\n",
       "      <td>0.560864</td>\n",
       "      <td>2.910267</td>\n",
       "      <td>0.864290</td>\n",
       "      <td>0.699434</td>\n",
       "      <td>2.284933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.424700e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>41.644670</td>\n",
       "      <td>-87.914428</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.150865e+06</td>\n",
       "      <td>1.196827e+06</td>\n",
       "      <td>41.844671</td>\n",
       "      <td>-87.705859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.497306e+06</td>\n",
       "      <td>1.979467e+06</td>\n",
       "      <td>41.892249</td>\n",
       "      <td>-87.664223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.010082e+06</td>\n",
       "      <td>2.245453e+06</td>\n",
       "      <td>41.939869</td>\n",
       "      <td>-87.634293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.345339e+06</td>\n",
       "      <td>3.846407e+06</td>\n",
       "      <td>42.021064</td>\n",
       "      <td>-87.526940</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Inspection ID     License #       Latitude      Longitude  \\\n",
       "count   1.182300e+05  1.182300e+05  118230.000000  118230.000000   \n",
       "mean    1.455131e+06  1.595582e+06      41.883736     -87.676102   \n",
       "std     6.388562e+05  9.020764e+05       0.079277       0.059985   \n",
       "min     4.424700e+04  0.000000e+00      41.644670     -87.914428   \n",
       "25%     1.150865e+06  1.196827e+06      41.844671     -87.705859   \n",
       "50%     1.497306e+06  1.979467e+06      41.892249     -87.664223   \n",
       "75%     2.010082e+06  2.245453e+06      41.939869     -87.634293   \n",
       "max     2.345339e+06  3.846407e+06      42.021064     -87.526940   \n",
       "\n",
       "                Risk  Violation Counts  Critical Violations Count  \\\n",
       "count  118230.000000     118230.000000              118230.000000   \n",
       "mean        1.295957          4.414971                   0.419893   \n",
       "std         0.560864          2.910267                   0.864290   \n",
       "min         1.000000          1.000000                   0.000000   \n",
       "25%         1.000000          2.000000                   0.000000   \n",
       "50%         1.000000          4.000000                   0.000000   \n",
       "75%         1.000000          6.000000                   0.000000   \n",
       "max         3.000000         34.000000                   9.000000   \n",
       "\n",
       "       Moderate Violations Count  Non-Critical Violations Count  \n",
       "count              118230.000000                  118230.000000  \n",
       "mean                    0.379421                       3.615656  \n",
       "std                     0.699434                       2.284933  \n",
       "min                     0.000000                       0.000000  \n",
       "25%                     0.000000                       2.000000  \n",
       "50%                     0.000000                       3.000000  \n",
       "75%                     1.000000                       5.000000  \n",
       "max                     6.000000                      23.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfi_dataset_selected_pickle.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load yelp and fast food restaurants dataset and combine with CFI dataset\n",
    "yelp_dataset = pd.read_pickle('business_details.pickle')\n",
    "fast_foods = pd.read_csv('datasets/FastFoodRestaurants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only keep the restaurants that appear more than once\n",
    "chain_counts = (fast_foods['name'].value_counts())\n",
    "fast_food_chains = chain_counts[chain_counts.values>=2].index.tolist()\n",
    "\n",
    "# To this list, we add some of the most famous chains that exist in the USA :\n",
    "fast_food_chains.extend(['Starbucks', 'KRISPY KRUNCHY CHICKEN', 'Caribou coffee',\\\n",
    "                         \"PEET'S COFFEE & TEA\", 'PHILZ COFFEE', 'INTELLIGENTSIA', 'PROTEIN BAR']) \n",
    "# added newly on 08.12.2019\n",
    "fast_food_chains.extend(['Starbucks Coffee', 'POPEYES FRIED CHICKEN', 'MCDONALDS RESTAURANT',\\\n",
    "                         \"POPEYE'S FRIED CHICKEN\",  'POPEYES FAMOUS FRIED CHICKEN', '#1 CHOP SUEY',\\\n",
    "                         \"NANDO'S PERI-PERI\", \"NANDO'S PERI PERI\", 'LITTLE CAESAR ENTERPRISES',\\\n",
    "                         \"MCDONALD'S RESTAURANT\", 'TARGET/STARBUCKS/PIZZA HUT', 'LITTLE CAESARS',\\\n",
    "                         'POPEYES FRIED CHICKEN REST', \"STARBUCK'S COFFEE\", 'BURGER KING #'])\n",
    "\n",
    "# We remove the char '\\'' for simplicity, transform everything to lowercase and remove duplicates\n",
    "fast_food_chains = set([chain_name.replace(\"\\'\", \"\").lower() for chain_name in fast_food_chains])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new column for Chain flag for food chains\n",
    "# We fill the column with 'N' for No' and 'Y' for 'Yes' if the establishment name exists in the fast_food_chains\n",
    "boolean_foodchains = pd.DataFrame(cfi_dataset_selected_pickle['AKA Name'].str.replace(\"\\'\", \"\")\\\n",
    "                                  .str.lower().isin(fast_food_chains)).rename(columns={\"AKA Name\": \"Chain flag temp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge two data frames to get the chain flag\n",
    "cfi_dataset_selected_pickle = cfi_dataset_selected_pickle.merge(boolean_foodchains, how='left',\n",
    "                                                                left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By mapping the 'Chain flag temp' booleans values to 'Y' for 'Yes' and 'N' for \"No\"\n",
    "temp = {True:'Y', False:'N'}\n",
    "cfi_dataset_selected_pickle['Chain flag'] = cfi_dataset_selected_pickle['Chain flag temp'].map(temp)\n",
    "cfi_dataset_selected_pickle = cfi_dataset_selected_pickle.drop(['Chain flag temp'], axis=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Milestone2 in 'DataCleaningAndExploratoryAnalysis.ipynb', we observed that over the inspection years, the data shows an increasing trend, except in the 2019 November. You can see the line graph that we had in the Milestone2. <img src=\"datasets/linegraph.png\" style=\"height:400px\"> \n",
    "Since by that time we gathered the data this is normal. But in order to avoid misinterpretations later in the risk score calculation, we will trim the data where the 'Inspection Date''s year and month is equal to '2019-11'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inspection Year</th>\n",
       "      <th>Inspection Month</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Inspection Year  Inspection Month  Count\n",
       "0               2010                 1    778\n",
       "1               2010                 2    897\n",
       "2               2010                 3    936\n",
       "3               2010                 4    911\n",
       "4               2010                 5    980\n",
       "..               ...               ...    ...\n",
       "114             2019                 7    866\n",
       "115             2019                 8    936\n",
       "116             2019                 9    768\n",
       "117             2019                10    775\n",
       "118             2019                11     78\n",
       "\n",
       "[119 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfi_dataset_selected_pickle['Inspection Year'] =  [x.year for x in cfi_dataset_selected_pickle['Inspection Date']]\n",
    "cfi_dataset_selected_pickle['Inspection Month'] =  [x.month for x in cfi_dataset_selected_pickle['Inspection Date']]\n",
    "group_by_inspection_date = cfi_dataset_selected_pickle.groupby(by=['Inspection Year', 'Inspection Month']).size().reset_index(name=\"Count\")\n",
    "group_by_inspection_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_length = len(cfi_dataset_selected_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We successfully removed 78 of the inpections data which come from the date of 2019.11.\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe where inspection date year is 2019 and inspection date month is 11\n",
    "cfi_dataset_201911 = cfi_dataset_selected_pickle[(cfi_dataset_selected_pickle['Inspection Year'] == 2019) & (cfi_dataset_selected_pickle['Inspection Month'] == 11)]\n",
    "combined = cfi_dataset_selected_pickle.append(cfi_dataset_201911)\n",
    "cfi_dataset_selected_pickle = combined[~combined.index.duplicated(keep=False)].reset_index()\n",
    "after_length = len(cfi_dataset_selected_pickle)\n",
    "print('We successfully removed {} of the inpections data which come from the date of 2019.11.'.format(before_length-after_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inspection ID</th>\n",
       "      <th>AKA Name</th>\n",
       "      <th>License #</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Community Area</th>\n",
       "      <th>Results</th>\n",
       "      <th>Violation Counts</th>\n",
       "      <th>Allergen Flag</th>\n",
       "      <th>Vomit or Diarrheal Flag</th>\n",
       "      <th>Critical Violations Count</th>\n",
       "      <th>Moderate Violations Count</th>\n",
       "      <th>Non-Critical Violations Count</th>\n",
       "      <th>Chain flag</th>\n",
       "      <th>Lowercased Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2290717</td>\n",
       "      <td>PAPA JOHN'S PIZZA</td>\n",
       "      <td>1545897</td>\n",
       "      <td>41.927995</td>\n",
       "      <td>-87.785752</td>\n",
       "      <td>Belmont Cragin</td>\n",
       "      <td>Pass w/ Conditions</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>papa john's pizza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2144588</td>\n",
       "      <td>SUBWAY</td>\n",
       "      <td>2529116</td>\n",
       "      <td>41.927995</td>\n",
       "      <td>-87.785752</td>\n",
       "      <td>Belmont Cragin</td>\n",
       "      <td>Fail</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>subway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2064444</td>\n",
       "      <td>PAPA JOHN'S PIZZA</td>\n",
       "      <td>1545897</td>\n",
       "      <td>41.927995</td>\n",
       "      <td>-87.785752</td>\n",
       "      <td>Belmont Cragin</td>\n",
       "      <td>Pass</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Y</td>\n",
       "      <td>papa john's pizza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059956</td>\n",
       "      <td>SUBWAY</td>\n",
       "      <td>2529116</td>\n",
       "      <td>41.927995</td>\n",
       "      <td>-87.785752</td>\n",
       "      <td>Belmont Cragin</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>subway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2060035</td>\n",
       "      <td>PAPA JOHN'S PIZZA</td>\n",
       "      <td>1545897</td>\n",
       "      <td>41.927995</td>\n",
       "      <td>-87.785752</td>\n",
       "      <td>Belmont Cragin</td>\n",
       "      <td>Fail</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Y</td>\n",
       "      <td>papa john's pizza</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Inspection ID           AKA Name  License #   Latitude  Longitude  \\\n",
       "0        2290717  PAPA JOHN'S PIZZA    1545897  41.927995 -87.785752   \n",
       "1        2144588             SUBWAY    2529116  41.927995 -87.785752   \n",
       "2        2064444  PAPA JOHN'S PIZZA    1545897  41.927995 -87.785752   \n",
       "3        2059956             SUBWAY    2529116  41.927995 -87.785752   \n",
       "4        2060035  PAPA JOHN'S PIZZA    1545897  41.927995 -87.785752   \n",
       "\n",
       "   Community Area             Results  Violation Counts Allergen Flag  \\\n",
       "0  Belmont Cragin  Pass w/ Conditions                 2             N   \n",
       "1  Belmont Cragin                Fail                 3             N   \n",
       "2  Belmont Cragin                Pass                 7             N   \n",
       "3  Belmont Cragin                Pass                 1             N   \n",
       "4  Belmont Cragin                Fail                 9             N   \n",
       "\n",
       "  Vomit or Diarrheal Flag  Critical Violations Count  \\\n",
       "0                       Y                          2   \n",
       "1                       N                          0   \n",
       "2                       N                          0   \n",
       "3                       N                          0   \n",
       "4                       N                          0   \n",
       "\n",
       "   Moderate Violations Count  Non-Critical Violations Count Chain flag  \\\n",
       "0                          0                              0          Y   \n",
       "1                          1                              2          Y   \n",
       "2                          0                              7          Y   \n",
       "3                          0                              1          Y   \n",
       "4                          0                              9          Y   \n",
       "\n",
       "     Lowercased Name  \n",
       "0  papa john's pizza  \n",
       "1             subway  \n",
       "2  papa john's pizza  \n",
       "3             subway  \n",
       "4  papa john's pizza  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's drop unnecessary columns\n",
    "cfi_dataset_selected_pickle = cfi_dataset_selected_pickle.drop(['DBA Name', 'Location', 'Violation Numbers', 'index', \n",
    "                                                                'Inspection Date', 'Inspection Year', \n",
    "                                                                'Inspection Month', 'Risk'], axis=1)\n",
    "cfi_dataset_selected_pickle['Lowercased Name'] = cfi_dataset_selected_pickle['AKA Name'].str.lower()\n",
    "cfi_dataset_selected_pickle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to calculate the rate of the failed ('Fail' results) inspections and successful (here we consider successful as combination of 'Pass' and 'Pass w/ Conditions') inspections we will do following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_results = cfi_dataset_selected_pickle[['Inspection ID', 'AKA Name', 'Lowercased Name', 'Chain flag',\n",
    "                                                  'License #', 'Community Area', 'Latitude', 'Longitude', 'Results']]\\\n",
    "                                        .groupby(by=['AKA Name', 'Lowercased Name', 'Chain flag', 'License #', \n",
    "                                                     'Community Area', 'Latitude', 'Longitude', 'Results'])\\\n",
    "                                        .size().reset_index(name=\"Count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the 'Pass w/ Conditions' to 'Pass' and keeping all other results as it is\n",
    "grouped_by_results['Results'] = grouped_by_results['Results'].map({'Pass w/ Conditions': 'Pass', \n",
    "                                                                  'Pass': 'Pass',\n",
    "                                                                  'Fail': 'Fail'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique establishments' names, chain flag, licence number, community areas, latitude and longitude\n",
    "grouped_aka_names_area = grouped_by_results[['AKA Name', 'Lowercased Name', 'Chain flag', 'License #', \n",
    "                                             'Community Area', 'Latitude', 'Longitude']].drop_duplicates()\\\n",
    "                                            .reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_aka_names_area = grouped_aka_names_area.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get sum over all 'Pass' results and 'Fail' results separately in a two variables\n",
    "def get_sum_results(df):\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis=1)\n",
    "    succes_sum = sum(df[(df['Results'] == 'Pass')]['Count'])\n",
    "    fail_sum = sum(df[(df['Results'] == 'Fail')]['Count'])\n",
    "    return [succes_sum, fail_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a new column named 'Successful Inspection Count' for total number of the pass counts\n",
    "grouped_aka_names_area['Successful Inspection Count'] = [get_sum_results(grouped_by_results[(grouped_by_results['AKA Name']==grouped_aka_names_area['AKA Name'][i]) & (grouped_by_results['Community Area']==grouped_aka_names_area['Community Area'][i])])[0] for i in range(len(grouped_aka_names_area))]\n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named 'Failed Inspection Count' for total number of the fail counts\n",
    "grouped_aka_names_area['Failed Inspection Count'] = [get_sum_results(grouped_by_results[(grouped_by_results['AKA Name']==grouped_aka_names_area['AKA Name'][i]) & (grouped_by_results['Community Area']==grouped_aka_names_area['Community Area'][i])])[-1] for i in range(len(grouped_aka_names_area))]\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = grouped_aka_names_area[grouped_aka_names_area['Chain flag']=='N']\n",
    "# a = a[['AKA Name','Latitude', 'Longitude']].drop_duplicates().reset_index()\n",
    "# a = a.drop('index', axis=1)\n",
    "# b = a.groupby(by=['AKA Name']).size().reset_index(name=\"Count\")\n",
    "# b1 = b[b['Count']>1].reset_index()\n",
    "# set(b1['AKA Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to aggregate the 'Vomit or Diarrheal Flag' feature we need to follow similar steps that we did above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_vomitDiarrheal = cfi_dataset_selected_pickle[['Inspection ID', 'AKA Name', 'Lowercased Name', 'Chain flag',\n",
    "                                                         'License #', 'Community Area', 'Latitude', 'Longitude', \n",
    "                                                         'Allergen Flag', 'Vomit or Diarrheal Flag']]\\\n",
    "                                        .groupby(by=['AKA Name', 'Lowercased Name', 'Chain flag', 'License #', \n",
    "                                                     'Community Area', 'Latitude', 'Longitude', \n",
    "                                                     'Vomit or Diarrheal Flag'])\\\n",
    "                                        .size().reset_index(name=\"Count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get sum over all 'Yes' and 'No' Vomit or Diarrheal Flag separately in a two variables\n",
    "def get_count_VomitDiarrheal(df):\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis=1)\n",
    "    yes_count = sum(df[(df['Vomit or Diarrheal Flag'] == 'Y')]['Count'])\n",
    "    no_count = sum(df[(df['Vomit or Diarrheal Flag'] == 'N')]['Count'])\n",
    "    return [yes_count, no_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named 'VomitDiarrheal Yes Counts' for total number of the yes counts\n",
    "grouped_aka_names_area['VomitDiarrheal Yes Counts'] = [get_count_VomitDiarrheal(grouped_by_vomitDiarrheal[(grouped_by_vomitDiarrheal['AKA Name']==grouped_aka_names_area['AKA Name'][i]) & (grouped_by_vomitDiarrheal['Community Area']==grouped_aka_names_area['Community Area'][i])])[0] for i in range(len(grouped_aka_names_area))]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named 'VomitDiarrheal No Counts' for total number of the no counts\n",
    "grouped_aka_names_area['VomitDiarrheal No Counts'] = [get_count_VomitDiarrheal(grouped_by_vomitDiarrheal[(grouped_by_vomitDiarrheal['AKA Name']==grouped_aka_names_area['AKA Name'][i]) & (grouped_by_vomitDiarrheal['Community Area']==grouped_aka_names_area['Community Area'][i])])[-1] for i in range(len(grouped_aka_names_area))]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to aggregate the 'Allergen Flag' feature we need to follow similar steps that we did above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_allergen = cfi_dataset_selected_pickle[['Inspection ID', 'AKA Name', 'Lowercased Name', 'Chain flag',\n",
    "                                                  'License #', 'Community Area', 'Latitude', 'Longitude', \n",
    "                                                  'Allergen Flag', 'Vomit or Diarrheal Flag']]\\\n",
    "                                        .groupby(by=['AKA Name', 'Lowercased Name', 'Chain flag', 'License #', \n",
    "                                                     'Community Area', 'Latitude', 'Longitude', 'Allergen Flag'])\\\n",
    "                                        .size().reset_index(name=\"Count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get sum over all 'Yes' and 'No' Vomit or Diarrheal Flag separately in a two variables\n",
    "def get_count_allergen(df):\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis=1)\n",
    "    yes_count = sum(df[(df['Allergen Flag'] == 'Y')]['Count'])\n",
    "    no_count = sum(df[(df['Allergen Flag'] == 'N')]['Count'])\n",
    "    return [yes_count, no_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named 'Allergen Yes Counts' for total number of the yes counts\n",
    "grouped_aka_names_area['Allergen Yes Counts'] = [get_count_allergen(grouped_by_allergen[(grouped_by_allergen['AKA Name']==grouped_aka_names_area['AKA Name'][i]) & (grouped_by_allergen['Community Area']==grouped_aka_names_area['Community Area'][i])])[0] for i in range(len(grouped_aka_names_area))]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named 'N VomitDiarrheal Counts' for total number of the no counts\n",
    "grouped_aka_names_area['Allergen No Counts'] = [get_count_allergen(grouped_by_allergen[(grouped_by_allergen['AKA Name']==grouped_aka_names_area['AKA Name'][i]) & (grouped_by_allergen['Community Area']==grouped_aka_names_area['Community Area'][i])])[-1] for i in range(len(grouped_aka_names_area))]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To aggregate all the violations count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_violations_sum = cfi_dataset_selected_pickle.groupby(by=['AKA Name', 'Lowercased Name', \n",
    "                                                                 'Chain flag', 'License #',\n",
    "                                                                 'Community Area', 'Latitude', \n",
    "                                                                 'Longitude'])\\\n",
    "                                                    .agg({'Violation Counts': 'sum',\n",
    "                                                          'Critical Violations Count': 'sum',\n",
    "                                                          'Moderate Violations Count': 'sum',\n",
    "                                                          'Non-Critical Violations Count': 'sum',\n",
    "                                                          }).reset_index()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two datasets that we aggregated above: grouped_violations_sum and grouped_aka_names_area\n",
    "features_dataframe = grouped_violations_sum.merge(grouped_aka_names_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for total counts and rate of counts and flags to use further analysis in score calculation\n",
    "features_dataframe['Total Inspections Result Counts'] = (features_dataframe['Successful Inspection Count'] + features_dataframe['Failed Inspection Count'])\n",
    "features_dataframe['Total VomitDiarrheal Flag Counts'] = (features_dataframe['VomitDiarrheal Yes Counts'] + features_dataframe['VomitDiarrheal No Counts'])\n",
    "features_dataframe['Total Allergen Flag Counts'] = (features_dataframe['Allergen Yes Counts'] + features_dataframe['Allergen No Counts'])\n",
    "\n",
    "features_dataframe['Success Ratio of Inspections'] = round(100*(features_dataframe['Successful Inspection Count']/features_dataframe['Total Inspections Result Counts']),2)\n",
    "features_dataframe['Failure Ratio of Inspections'] = round(100*(features_dataframe['Failed Inspection Count']/features_dataframe['Total Inspections Result Counts']),2)\n",
    "features_dataframe['Yes Ratio of VomitDiarrheal']  = round(100*(features_dataframe['VomitDiarrheal Yes Counts']/features_dataframe['Total VomitDiarrheal Flag Counts']),2)\n",
    "features_dataframe['No Ratio of VomitDiarrheal']   = round(100*(features_dataframe['VomitDiarrheal No Counts']/features_dataframe['Total VomitDiarrheal Flag Counts']),2)\n",
    "features_dataframe['Yes Ratio of Allergen']        = round(100*(features_dataframe['Allergen Yes Counts']/features_dataframe['Total Allergen Flag Counts']),2)\n",
    "features_dataframe['No Ratio of Allergen']         = round(100*(features_dataframe['Allergen No Counts']/features_dataframe['Total Allergen Flag Counts']),2)\n",
    "\n",
    "features_dataframe['Critical Violations Ratio']     = round(100*(features_dataframe['Critical Violations Count']/features_dataframe['Violation Counts']),2)\n",
    "features_dataframe['Moderate Violations Ratio']     = round(100*(features_dataframe['Moderate Violations Count']/features_dataframe['Violation Counts']),2)\n",
    "features_dataframe['Non-Critical Violations Ratio'] = round(100*(features_dataframe['Non-Critical Violations Count']/features_dataframe['Violation Counts']),2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Yelp dataset to find out restaurants' ratings and price tags given by Yelp users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinates.latitude</th>\n",
       "      <th>coordinates.longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>Lowercased Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.820629</td>\n",
       "      <td>-87.699310</td>\n",
       "      <td>Carniceria Y Fruteria Los Altos</td>\n",
       "      <td>$</td>\n",
       "      <td>3.5</td>\n",
       "      <td>carniceria y fruteria los altos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.878517</td>\n",
       "      <td>-87.626351</td>\n",
       "      <td>Al's Beef</td>\n",
       "      <td>$</td>\n",
       "      <td>3.0</td>\n",
       "      <td>al's beef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.968245</td>\n",
       "      <td>-87.715123</td>\n",
       "      <td>Peking Mandarin</td>\n",
       "      <td>$</td>\n",
       "      <td>4.0</td>\n",
       "      <td>peking mandarin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.944680</td>\n",
       "      <td>-87.727680</td>\n",
       "      <td>La Humita</td>\n",
       "      <td>$$</td>\n",
       "      <td>4.0</td>\n",
       "      <td>la humita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.968636</td>\n",
       "      <td>-87.716194</td>\n",
       "      <td>Chicago Produce</td>\n",
       "      <td>$</td>\n",
       "      <td>3.5</td>\n",
       "      <td>chicago produce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   coordinates.latitude  coordinates.longitude  \\\n",
       "0             41.820629             -87.699310   \n",
       "1             41.878517             -87.626351   \n",
       "2             41.968245             -87.715123   \n",
       "3             41.944680             -87.727680   \n",
       "4             41.968636             -87.716194   \n",
       "\n",
       "                              name price  rating  \\\n",
       "0  Carniceria Y Fruteria Los Altos     $     3.5   \n",
       "1                        Al's Beef     $     3.0   \n",
       "2                  Peking Mandarin     $     4.0   \n",
       "3                        La Humita    $$     4.0   \n",
       "4                  Chicago Produce     $     3.5   \n",
       "\n",
       "                   Lowercased Name  \n",
       "0  carniceria y fruteria los altos  \n",
       "1                        al's beef  \n",
       "2                  peking mandarin  \n",
       "3                        la humita  \n",
       "4                  chicago produce  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the fetaures that we need\n",
    "yelp_dataset = yelp_dataset[['coordinates.latitude', 'coordinates.longitude', 'name', 'price', 'rating']]\n",
    "yelp_dataset['Lowercased Name'] = yelp_dataset['name'].str.lower()\n",
    "yelp_dataset = yelp_dataset.drop_duplicates()\n",
    "yelp_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$', '$$', nan, '$$$', '$$$$'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine distinct price levels in the yelp dataset price column and map them to a numerical grade to make it easier\n",
    "# further analysis on that feature\n",
    "yelp_dataset['price'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for price values:\n",
    "# 0 for nan price value \n",
    "# 1 for '$' price level \n",
    "# 2 for '$$' price level \n",
    "# 3 for '$$$' price level \n",
    "# 4 for '$$$$' price level  \n",
    "temp = {'$':1, '$$':2, np.nan:0, '$$$':3, '$$$$':4}\n",
    "yelp_dataset['Price'] = yelp_dataset['price'].map(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lowercased Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!hello tacos!</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 chop suey</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000 liquors</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101 n wacker dr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1048 sky lounge - wrigley rooftop</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Lowercased Name  Price  rating\n",
       "0                      !hello tacos!    2.0     3.5\n",
       "1                        1 chop suey    0.0     2.5\n",
       "2                       1000 liquors    2.0     2.5\n",
       "3                    101 n wacker dr    0.0     4.0\n",
       "4  1048 sky lounge - wrigley rooftop    0.0     3.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate the Yelp dataset to have the Price, review and rating for each establishment\n",
    "yelp_dataset_grouped = yelp_dataset.groupby(by=['Lowercased Name'])\\\n",
    "                                   .agg({'Price':'median',  \n",
    "                                         'rating':'mean'}).reset_index()\n",
    "yelp_dataset_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_dataframe = features_dataframe.merge(yelp_dataset_grouped, how='left', on='Lowercased Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle\n",
    "#all_features_dataframe.to_pickle('pickles/all_features_dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "TO DO: Calculate Score\n",
    "\n",
    "Idea:\n",
    "\n",
    "We will compute the **Risk score** using a weighted sum of the features by their importance and use MinMax to normalize the score for each restaurant at the end\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_dataframe = pd.read_pickle('pickles/all_features_dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
